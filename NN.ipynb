{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN algorithm and Conformal Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries needed for Iris and ionosphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:- Here in this Assignment I have implemented code for KNN without using library \n",
    "\n",
    "but also done testing of KNN algorithm with Sklearn.neighbors library . \n",
    "\n",
    "So I have imported that for testing purpose to check either my code is working properly or not.\n",
    "\n",
    "please check the code . \n",
    "\n",
    "Also Tried my DOB here but it was giving 0 errors so I have changed random state to 530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "iris=load_iris() #loading iris dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': '/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/iris.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris #checking data of Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building General function for K (using this for both iris and ionospehere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "irst we will find index of sorted array without sort function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the array and finding the index \n",
    "\n",
    "def sorting_Common_array(array):\n",
    "    n=array.shape[0]\n",
    "    sort_index=np.zeros(n)\n",
    "    count=0\n",
    "    for j in range(n):\n",
    "        result = 0\n",
    "        for i in range(n): \n",
    "            if (array[i] < array[j]): \n",
    "                result += 1\n",
    "            if (array[i] == array[j] and i < j): \n",
    "                result += 1\n",
    "        \n",
    "        sort_index[count]=result\n",
    "        count+=1\n",
    "    return sort_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will find k nearest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding k nearest values  \n",
    "def fetch_k_values_Common(array,k):\n",
    "    k_values=np.zeros(k)\n",
    "    count=0\n",
    "    for v in range(y_train.shape[0]):\n",
    "        if array[0,v,0]<=k-1:\n",
    "            k_values[count]=array[0,v,1]\n",
    "            count+=1\n",
    "    return k_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN common function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing library needed for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn function definition \n",
    "def KNNfit(X_train,y_train,X_test,y_test,k): #here k indicates the neighbour counts\n",
    "    start = time.time()\n",
    "    y_predict=np.zeros(y_test.shape[0])\n",
    "    # finding Euclidien distance between test data and training data \n",
    "    for i in range(X_test.shape[0]):\n",
    "        my_array=np.zeros(X_train.shape[0])\n",
    "        for j in range(X_train.shape[0]):\n",
    "            my_array[j]=la.norm(X_test[i,:]-X_train[j,:])\n",
    "    # Finding index and sorting given array    \n",
    "        sorted_array=sorting_Common_array(my_array)\n",
    "    # zipping sorted array with the labels      \n",
    "        d=np.dstack((sorted_array,y_train)) \n",
    "    # finding the k nearest sample labels      \n",
    "        max_label_count=fetch_k_values_Common(d,k)\n",
    "    # voting the given labels\n",
    "        (values,counts) = np.unique(max_label_count,return_counts=True)\n",
    "        ind=np.argmax(counts)\n",
    "        y_predict[i]=int(values[ind])     \n",
    "   \n",
    "    \n",
    "    print('\\nPrediction time for this code is: ',\"%.2f\" %(time.time() - start),\"seconds\")    \n",
    "     # finding number of errors \n",
    "    print('Number of errors: ',y_test.size-np.count_nonzero(y_predict == y_test))\n",
    "     # finding the error rate  \n",
    "    print('Error Rate is: ',(y_test.size-np.count_nonzero(y_predict == y_test))/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing KNN for IRIS now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting data into training and testing data here first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(iris['data'],iris['target'],random_state=530)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sizes of the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing purpose used this one\n",
    "from sklearn.neighbors import KNeighborsClassifier #I have validated my score with sklearn neighbors score and done comparison here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparison with sklearn.neighbors library for KNN (IRIS dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here to check my created logic for KNN is giving same o/p or not I am comparing both KNN algorithm O/p and my o/p togethere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Result of  KNNClassifier when k=3 ******\n",
      "\n",
      "\n",
      "Prediction time for Iris dataset code is:  0.01 seconds\n",
      "Number of errors:  2\n",
      "Error Rate is:  0.052631578947368474\n"
     ]
    }
   ],
   "source": [
    "print(\"****** Result of  KNNClassifier when k=3 ******\\n\")\n",
    "import time\n",
    "start = time.time() #to check how much time taken by KNN algorithm and my code so importing Time here\n",
    "knn = KNeighborsClassifier(n_neighbors=3) # here we are taking 3 nearest neighbour\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('\\nPrediction time for Iris dataset code is: ',\"%.2f\" %(time.time() - start),\"seconds\")\n",
    "\n",
    "print(\"Number of errors: \",y_test.size-np.count_nonzero(y_pred == y_test)) # finding the error line\n",
    "\n",
    "print(\"Error Rate is: \",1-knn.score(X_test,y_test)) # error rate line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without using KNNClassifier we are checking our created common function o/p and how it works here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Result of Iris dataset (my code) without using KNNClassifier when k=3  ****\n",
      "\n",
      "\n",
      "Prediction time for this code is:  0.30 seconds\n",
      "Number of errors:  2\n",
      "Error Rate is:  0.05263157894736842\n"
     ]
    }
   ],
   "source": [
    "print(\"**** Result of Iris dataset (my code) without using KNNClassifier when k=3  ****\\n\")\n",
    "KNNfit(X_train,y_train,X_test,y_test,3)\n",
    "import time\n",
    "start = time.time()\n",
    "#print('\\npredicted in: ',\"%.2f\" %(time.time() - start),\"seconds\") # no need of this as already in function added this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Result of  KNNClassifier when k=1 ******\n",
      "\n",
      "\n",
      "Prediction time for Iris dataset code is:  0.00 seconds\n",
      "Number of errors:  1\n",
      "Error Rate is:  0.02631578947368418\n"
     ]
    }
   ],
   "source": [
    "print(\"****** Result of  KNNClassifier when k=1 ******\\n\")\n",
    "import time\n",
    "start = time.time() #to check how much time taken by KNN algorithm and my code so importing Time here\n",
    "knn = KNeighborsClassifier(n_neighbors=1) # here we are taking 3 nearest neighbour\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('\\nPrediction time for Iris dataset code is: ',\"%.2f\" %(time.time() - start),\"seconds\")\n",
    "\n",
    "print(\"Number of errors: \",y_test.size-np.count_nonzero(y_pred == y_test)) # finding the error line\n",
    "\n",
    "print(\"Error Rate is: \",1-knn.score(X_test,y_test)) # error rate line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Result of Iris dataset (my code) without using KNNClassifier when k=1  ****\n",
      "\n",
      "\n",
      "Prediction time for this code is:  0.29 seconds\n",
      "Number of errors:  1\n",
      "Error Rate is:  0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"**** Result of Iris dataset (my code) without using KNNClassifier when k=1  ****\\n\")\n",
    "KNNfit(X_train,y_train,X_test,y_test,1)\n",
    "import time\n",
    "start = time.time()\n",
    "#print('\\npredicted in: ',\"%.2f\" %(time.time() - start),\"seconds\") # no need of this as already in function added this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here it is observed that when we are using sklearn.neighbors library for KNN its taking very less time while our created code without using library is taking large time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing KNN for Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.genfromtxt(\"//Users/Downloads/ionosphere.txt\",delimiter=\",\",usecols=np.arange(34))\n",
    "y=np.genfromtxt(\"//Users/Downloads/ionosphere.txt\",delimiter=\",\",usecols=34,dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.     ,  0.     ,  0.99539, ..., -0.54487,  0.18641, -0.453  ],\n",
       "       [ 1.     ,  0.     ,  1.     , ..., -0.06288, -0.13738, -0.02447],\n",
       "       [ 1.     ,  0.     ,  1.     , ..., -0.2418 ,  0.56045, -0.38238],\n",
       "       ...,\n",
       "       [ 1.     ,  0.     ,  0.94701, ...,  0.00442,  0.92697, -0.00577],\n",
       "       [ 1.     ,  0.     ,  0.90608, ..., -0.03757,  0.87403, -0.16243],\n",
       "       [ 1.     ,  0.     ,  0.8471 , ..., -0.06678,  0.85764, -0.06151]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X #checking data loaded or not properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting data into training and testing data here first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=530)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sizes of the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 34)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #checking size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 34)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparison with sklearn.neighbors library for KNN (Ionosphere dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here to check my created logic for KNN is giving same o/p or not I am comparing both KNN algorithm O/p and my o/p togethere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR 3NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Result of Ionosphere dataset(my code) without using KNNClassifier when k=3 ****\n",
      "\n",
      "\n",
      "Prediction time for this code is:  3.41 seconds\n",
      "Number of errors:  10\n",
      "Error Rate is:  0.11363636363636363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"**** Result of Ionosphere dataset(my code) without using KNNClassifier when k=3 ****\\n\")\n",
    "\n",
    "KNNfit(X_train,y_train,X_test,y_test,3) # nearest neighbour is 3 here K=3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Result of  KNNClassifier when k=3 ******\n",
      "\n",
      "\n",
      "Prediction time for Ionosphere dataset code is:  0.01 seconds\n",
      "Number of errors:  10\n",
      "Error Rate is:  0.11363636363636365\n"
     ]
    }
   ],
   "source": [
    "print(\"****** Result of  KNNClassifier when k=3 ******\\n\")\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('\\nPrediction time for Ionosphere dataset code is: ',\"%.2f\" %(time.time() - start),\"seconds\")\n",
    "\n",
    "print(\"Number of errors: \",y_test.size-np.count_nonzero(y_pred == y_test))\n",
    "\n",
    "print(\"Error Rate is: \",1-knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Result of Ionosphere dataset(my code) without using KNNClassifier when k=1  ****\n",
      "\n",
      "\n",
      "Prediction time for this code is:  3.43 seconds\n",
      "Number of errors:  8\n",
      "Error Rate is:  0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"**** Result of Ionosphere dataset(my code) without using KNNClassifier when k=1  ****\\n\")\n",
    "\n",
    "KNNfit(X_train,y_train,X_test,y_test,1) # nearest neighbour is 1 here K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Result of  KNNClassifier when k=1 ******\n",
      "\n",
      "\n",
      "Prediction time for Ionosphere dataset code is:  3.47 seconds\n",
      "Number of errors:  8\n",
      "Error Rate is:  0.09090909090909094\n"
     ]
    }
   ],
   "source": [
    "print(\"****** Result of  KNNClassifier when k=1 ******\\n\")\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('\\nPrediction time for Ionosphere dataset code is: ',\"%.2f\" %(time.time() - start),\"seconds\")\n",
    "\n",
    "print(\"Number of errors: \",y_test.size-np.count_nonzero(y_pred == y_test))\n",
    "\n",
    "print(\"Error Rate is: \",1-knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here it is observed that when we are using sklearn.neighbors library for KNN its taking very less time while our created code without using library is taking large time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conformal prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the examples we solve. \n",
    "flow of finding conformal prediction is\n",
    "1) conformity score (diff/same class) i.e finding difference between nearest sample of different class  and nearest sample of same class\n",
    "2)then we will do ranking\n",
    "3) calculate P_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating common function for conformal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition along with parameters\n",
    "def conformity_score_Common(X_train,y_train,X_test,y_test,i,j,labels):\n",
    "    \n",
    "    import math\n",
    "    # concatenating (X,y) of training set\n",
    "    x_train_concat=np.concatenate((X_train,y_train[:,None]),axis=1)\n",
    "    # concatenating (X,y) of one test set per function\n",
    "    x_test_add=np.concatenate((X_test[i:i+1,],labels[j:j+1,None]),axis=1)\n",
    "    # concatenating (X,y) of all training set and one test set\n",
    "    x_train_test_concat=np.concatenate((x_train_concat,x_test_add))\n",
    "    # concatenating y of training set and one test set\n",
    "    y_concat=np.concatenate((y_train,labels[j:j+1]))\n",
    "    # assign size of CF_score array\n",
    "    CF_score=np.zeros(x_train_test_concat.shape[0])\n",
    "    # iterate through each (x,y) of set and find distance\n",
    "    for k in range(x_train_test_concat.shape[0]):\n",
    "        arr_same=[]\n",
    "        arr_diff=[]\n",
    "        for l in range(x_train_test_concat.shape[0]):\n",
    "            if k!=l:\n",
    "                # find distance between sample of same class\n",
    "                if x_train_test_concat[k,-1]==y_concat[l]:\n",
    "                    arr_same.append(la.norm(x_train_test_concat[k,:-1]-x_train_test_concat[l,:-1]))\n",
    "                # find distance between sample of different class\n",
    "                else:\n",
    "                    arr_diff.append(la.norm(x_train_test_concat[k,:-1]-x_train_test_concat[l,:-1]))\n",
    "    # exception handling for ZeroDivisionError\n",
    "    # using formula -(distance between nearest sample of same class)/(distance between nearest sample of diff class)\n",
    "        try:\n",
    "            CF_score[k]=(min(arr_diff)/min(arr_same)) \n",
    "        except ZeroDivisionError:\n",
    "            CF_score[k]=np.inf\n",
    "    return CF_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " exception handling for ZeroDivisionError\n",
    " using formula -(distance between nearest sample of same class)/(distance between nearest sample of diff class)\n",
    "getting divide by 0 error here. SO using Try and catch to handle this exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating code for P_values now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating p value of each conformal score array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating p value of each CF_score array\n",
    "def p_value(CF_score):\n",
    "    count=0\n",
    "    for m in range(CF_score.shape[0]):\n",
    "    \n",
    "        if CF_score[m]<=CF_score[-1]:\n",
    "            count+=1\n",
    "    p_value=(count/CF_score.shape[0])\n",
    "    return p_value\n",
    "import numpy as np\n",
    "p_value(np.array([1,2,3,6,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculation of p_value of each test sample for every label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-dfcf471524c3>:30: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  CF_score[k]=(min(arr_diff)/min(arr_same))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00378788, 0.74621212],\n",
       "       [0.00378788, 0.55681818],\n",
       "       [0.17424242, 0.10606061],\n",
       "       [0.12121212, 0.15530303],\n",
       "       [0.00378788, 0.66666667],\n",
       "       [0.10227273, 0.1780303 ],\n",
       "       [0.23863636, 0.08333333],\n",
       "       [0.17045455, 0.10606061],\n",
       "       [0.47727273, 0.00757576],\n",
       "       [0.00378788, 0.86742424],\n",
       "       [0.00378788, 0.73106061],\n",
       "       [0.1969697 , 0.09848485],\n",
       "       [0.04545455, 0.34848485],\n",
       "       [0.00378788, 0.85606061],\n",
       "       [1.        , 0.00757576],\n",
       "       [0.16666667, 0.11742424],\n",
       "       [0.00378788, 0.79924242],\n",
       "       [0.25378788, 0.07954545],\n",
       "       [0.18181818, 0.10227273],\n",
       "       [0.17424242, 0.10606061],\n",
       "       [0.06439394, 0.29166667],\n",
       "       [0.23106061, 0.09469697],\n",
       "       [0.00378788, 0.65530303],\n",
       "       [0.00757576, 0.66287879],\n",
       "       [0.00378788, 0.70075758],\n",
       "       [0.00378788, 0.71590909],\n",
       "       [0.00378788, 1.        ],\n",
       "       [0.21590909, 0.09848485],\n",
       "       [0.00378788, 0.81060606],\n",
       "       [0.00378788, 0.93939394],\n",
       "       [0.00757576, 0.49242424],\n",
       "       [0.21212121, 0.09848485],\n",
       "       [0.00378788, 0.91287879],\n",
       "       [0.05681818, 0.29166667],\n",
       "       [0.00378788, 0.81439394],\n",
       "       [0.00757576, 0.55681818],\n",
       "       [0.00378788, 0.96212121],\n",
       "       [0.04924242, 0.34090909],\n",
       "       [0.17045455, 0.10606061],\n",
       "       [0.00378788, 0.55681818],\n",
       "       [0.00378788, 0.87121212],\n",
       "       [0.00378788, 0.59469697],\n",
       "       [0.02651515, 0.40909091],\n",
       "       [0.00378788, 0.9469697 ],\n",
       "       [0.00757576, 0.55681818],\n",
       "       [0.00757576, 0.48106061],\n",
       "       [0.52651515, 0.00757576],\n",
       "       [0.00378788, 0.96969697],\n",
       "       [0.00378788, 0.95833333],\n",
       "       [0.00378788, 0.87121212],\n",
       "       [0.00757576, 0.46212121],\n",
       "       [0.02651515, 0.40151515],\n",
       "       [0.00378788, 0.85227273],\n",
       "       [0.03409091, 0.375     ],\n",
       "       [0.00378788, 0.64772727],\n",
       "       [0.27651515, 0.06439394],\n",
       "       [0.00757576, 0.48106061],\n",
       "       [0.00378788, 0.72348485],\n",
       "       [0.00378788, 0.85606061],\n",
       "       [0.00378788, 0.77651515],\n",
       "       [0.00757576, 0.60606061],\n",
       "       [0.00378788, 0.81060606],\n",
       "       [0.29924242, 0.05681818],\n",
       "       [0.00378788, 0.96969697],\n",
       "       [0.03030303, 0.39393939],\n",
       "       [0.09848485, 0.18181818],\n",
       "       [0.00378788, 0.75      ],\n",
       "       [0.05681818, 0.29924242],\n",
       "       [0.00378788, 0.81060606],\n",
       "       [0.00378788, 0.87121212],\n",
       "       [0.15151515, 0.13257576],\n",
       "       [0.00757576, 0.46590909],\n",
       "       [0.17045455, 0.10606061],\n",
       "       [0.00757576, 0.64015152],\n",
       "       [0.17424242, 0.10606061],\n",
       "       [0.02272727, 0.41287879],\n",
       "       [0.00378788, 0.62121212],\n",
       "       [0.00757576, 0.48106061],\n",
       "       [0.11742424, 0.15909091],\n",
       "       [0.00378788, 0.72348485],\n",
       "       [0.16666667, 0.11742424],\n",
       "       [0.00378788, 0.98484848],\n",
       "       [0.1780303 , 0.10227273],\n",
       "       [0.14393939, 0.13636364],\n",
       "       [0.27272727, 0.06818182],\n",
       "       [0.02272727, 0.41287879],\n",
       "       [0.00378788, 0.81439394],\n",
       "       [0.09848485, 0.19318182]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculation of p_value of each test sample for every label\n",
    "def p_value_array_for_each(X_train,X_test,y_train,y_test,labels):\n",
    "    \n",
    "    labels_array=np.zeros((X_test.shape[0],labels.shape[0]))\n",
    "    for ii in range(X_test.shape[0]):\n",
    "        for jj in range(labels.shape[0]):\n",
    "            labels_array[ii,jj]=p_value(conformity_score_Common(X_train,y_train,X_test,y_test,ii,jj,labels))\n",
    "    return labels_array \n",
    "\n",
    "labels=np.unique(y_train)\n",
    "p_value_array_for_each(X_train,X_test,y_train,y_test,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function definition - calculation of average false P value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of average false p_value\n",
    "def average_false_pvalue_CF(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    labels=np.unique(y_train)\n",
    "    p_value_array_FP=p_value_array_for_each(X_train,X_test,y_train,y_test,labels)\n",
    "    sum=0\n",
    "    for ii in range(p_value_array_FP.shape[0]):\n",
    "        for jj in range(labels.shape[0]):\n",
    "            # summation of false_pvalues \n",
    "            if labels[jj]!=y_test[ii]:\n",
    "                sum+=p_value_array_FP[ii,jj]\n",
    "    # average of false_p_value\n",
    "    return (sum/(X_test.shape[0]*(labels.shape[0]-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculation of average false P value of iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-dfcf471524c3>:30: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  CF_score[k]=(min(arr_diff)/min(arr_same))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average False P_value of iris data set is :  0.010945505356311143\n",
      "\n",
      "Time taken by program:  9.04 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris['data'],iris['target'],random_state=503)\n",
    "print('Average False P_value of iris data set is : ',average_false_pvalue_CF(X_train,X_test,y_train,y_test))\n",
    "print('\\nTime taken by program: ',\"%.2f\" %(time.time() - start),\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculation of average false P value of ionosphere dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-dfcf471524c3>:30: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  CF_score[k]=(min(arr_diff)/min(arr_same))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average false P_value of ionoshphere data set is  0.0636191460055097\n",
      "\\Time taken by program:  80.55 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=503)\n",
    "print('Average false P_value of ionoshphere data set is ',average_false_pvalue_CF(X_train,X_test,y_train,y_test))\n",
    "print('\\Time taken by program: ',\"%.2f\" %(time.time() - start),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
